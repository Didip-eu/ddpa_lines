{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Middle Lower German Corpus transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from pathlib import Path\n",
    "from pathlib import PurePosixPath\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_name = \"CorA-ReN-XML_1.1\" #only used for export file name\n",
    "directoryPath = \"../data/in/REN/CorA-ReN-XML_1.1/\"\n",
    "fileExtension = \".xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cei_files(base_dir):\n",
    "    for entry in os.scandir(base_dir):\n",
    "        if entry.is_file() and entry.name.endswith(fileExtension):\n",
    "            yield Path(entry.path)\n",
    "        elif entry.is_dir():\n",
    "            yield from get_cei_files(entry.path)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [f\"{PurePosixPath(path)}\" for path in get_cei_files(directoryPath)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = [\"ids\", \"names\", \"header\", \"tokens_anno_ascii\", \"tokens_anno_utf\", \"tokens_dipl_utf\", \"topics\", \"textTypes\", \"genres\", \"languages\", \"languageTypes\", \"languageRegions\", \"languageAreas\", \"centuries\", \"dates\"]\n",
    "ids, names, header, tokens_anno_ascii, tokens_anno_utf, tokens_dipl_utf, topics, textTypes, genres, languages, languageTypes, languageRegions, languageAreas, centuries, dates = ([] for i in range(len(lists)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in paths:\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        root = etree.parse(f).getroot()\n",
    "        ids.append(root.xpath(\"/text/@id\", smart_strings = False))\n",
    "        names.append(root.xpath(\"/text/cora-header/@name\", smart_strings = False))\n",
    "        header.append(root.xpath(\"/text/header/text()\", smart_strings = False))\n",
    "        tokens_anno_ascii.append(root.xpath(\"/text/token/anno/@ascii\", smart_strings = False))\n",
    "        tokens_anno_utf.append(root.xpath(\"/text/token/anno/@utf\", smart_strings = False))\n",
    "        tokens_dipl_utf.append(root.xpath(\"/text/token/dipl/@utf\", smart_strings = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = list(zip(ids, names, header, tokens_anno_ascii, tokens_anno_utf, tokens_dipl_utf))\n",
    "contents_full = pd.DataFrame(contents).rename(columns={0: \"ids\", 1: \"names\", 2: \"header\", 3: \"tokens_anno_ascii\", 4: \"tokens_anno_utf\", 5: \"tokens_dipl_utf\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_full[\"string_anno_ascii\"] = contents_full[\"tokens_anno_ascii\"].str.join(sep=\" \")\n",
    "contents_full[\"string_anno_ascii\"] = [re.sub(r' . ', '. ', str(x)) for x in contents_full[\"string_anno_ascii\"]]\n",
    "\n",
    "contents_full[\"string_anno_utf\"] = contents_full[\"tokens_anno_utf\"].str.join(sep=\" \")\n",
    "contents_full[\"string_anno_utf\"] = [re.sub(r' . ', '. ', str(x)) for x in contents_full[\"string_anno_utf\"]]\n",
    "\n",
    "contents_full[\"string_dipl_utf\"] = contents_full[\"tokens_dipl_utf\"].str.join(sep=\" \")\n",
    "contents_full[\"string_dipl_utf\"] = [re.sub(r' . ', '. ', str(x)) for x in contents_full[\"string_dipl_utf\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name output according to subcorpus\n",
    "\n",
    "timemarker = datetime.today().strftime('%Y-%m-%d-%H%M')\n",
    "contents_full.to_json(f\"../data/out/{corpus_name}_{timemarker}.json\")\n",
    "contents_full.to_parquet(f\"../data/out/{corpus_name}_{timemarker}.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('didipcv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51de90f0d358e009ce9df81fe88f979b0f6e2c5f2b81c54b9ff289164d1b3424"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
