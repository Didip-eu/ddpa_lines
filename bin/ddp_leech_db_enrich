#!/usr/bin/env python3

"""
Leeches .xml-files in target file structure system with the main purpose of building image urls.
"""

import os
import random
from pathlib import Path
from pathlib import PurePosixPath
from pprint import pprint
import shutil
from typing import Dict, Generator, List, Literal, get_args # where to put choices in program?
from lxml import etree
import fargv
from tqdm import tqdm
import hashlib
import glob

from urllib.parse import urlparse


from ddp_util import decompose_chatomid, get_path_generator, get_path_list


### Type options
base_url_choices = Literal["archive", "collection"] # TODO: see top


def filter_image_base_url(image_base):
    exceptions = [
    "www.monasterium.net",
    "www.monasterium.net/",
    "www.monasterium.net/*",
    "images.monasterium.net/*",
    "http://www.monasterium.net/",
    "http://www.monasterium.net",
    "http://www.monasterium.net/*",
    "http://images.monasterium.net/*",
    "http://www.monasterium.net/Diplomatico_Viewerbild.jpg"
    ]

    if image_base in exceptions:
        image_base = "Invalid" #TODO: generalize and extend this to empty strings, which are now handled in the get_image_base_urls function
    return image_base
    

def get_image_base_urls(paths, mode: base_url_choices):
    """
    Returns (filtered) base image paths.
    """
    options = get_args(base_url_choices)
    assert mode in options, f"'{mode}' is not in {options}"

    pprint("Parsing curation image base paths.")

    file_locations = {}
    namespaces = {"xrx": "http://www.monasterium.net/NS/xrx", "atom": "http://www.w3.org/2005/Atom", "cei": "http://www.monasterium.net/NS/cei"}

    if mode == "archive":
        pprint("Mode: archives")        
        for file in tqdm(paths):
            with open(file, 'r', encoding='utf-8') as current:
                tree = etree.parse(current)
                image_server_base_url = "".join(tree.xpath("//xrx:param[@name='image-server-base-url']/text()", namespaces = namespaces))
                image_base = filter_image_base_url("None" if (image_server_base_url  == "") else image_server_base_url)
                image_access = tree.xpath("xrx:param[@name='image-access']/text()", namespaces = namespaces)
                #restricted = True if image_access == ("free" or "Free") else False #have not seen capitalized F but just to make sure..
                file_locations[file] = image_base 
    elif mode =="collection":
        pprint("Mode: collections")
        for file in tqdm(paths):
            with open(file, 'r', encoding='utf-8') as current:
                tree = etree.parse(current)
                image_server_address = "".join(tree.xpath("//cei:image_server_address/text()", namespaces = namespaces))
                image_server_folder = "".join(tree.xpath("//cei:image_server_folder/text()", namespaces = namespaces))              
                image_base = filter_image_base_url("None" if ((image_server_address or image_server_folder) == "") else f"{image_server_address}/{image_server_folder}") #TODO: check for misconstruced ones by adding http://
                file_locations[file] = image_base
                #restricted = False #default since it's unclear whether <cei:publicationStmt><cei:availability n="ENRICH" status="restricted"/></cei:publicationStmt> in fonds plays any role
    # TODO: #also maybe relevant <xrx:keyword>Retrodigitalisierte Urkundeneditionen</xrx:keyword> bzw. <cei:sourceDesc><cei:p>Export aus Google Daten</cei:p>
    else:
        raise ValueError("Invalid mode.")
    #pprint(file_locations)
    return file_locations #, restricted


def create_image_base_url_files(file_locations):
    """
    Creates .txt-files with the image base url at curation-level.
    """
    pprint("Creating .txt files at curation-level.")

    for path, image_base in tqdm(file_locations.items()):
        file_path = Path(path)
        target_path = f"{file_path.parent}/image_base_url.txt"
        #target_path = f"{file_path.parent}/{file_path.with_suffix('').stem}.image_base_url.txt"
        if image_base != "":
            with open(target_path, 'w', encoding="utf-8") as p:
                p.write(image_base)
        else:
            continue


def create_image_refs(paths): #here, refs is understood as a reference to an object, be it a valid URL or a file-name that is later resolved
    pprint("Parsing charter files for image paths. Building image refs on charter level.")

    namespaces = {"xrx": "http://www.monasterium.net/NS/xrx", "atom": "http://www.w3.org/2005/Atom", "cei": "http://www.monasterium.net/NS/cei"}

    for file_path in tqdm(paths):
        with open(file_path, 'r', encoding='utf-8') as current:
            tree = etree.parse(current)
            original = tree.xpath("//cei:witnessOrig/cei:figure/cei:graphic/@url", namespaces = namespaces)
            copy = tree.xpath("//cei:witness/cei:figure/cei:graphic/@url", namespaces = namespaces)
        file_path = Path(file_path)
        file_folder = file_path.parent
        images = original + copy
        target_path = f"{file_folder}/{file_folder.stem}.image_refs.txt"            
        for i in images:
            with open(target_path, mode="w", encoding="utf-8") as current:
                for image_ref in images:
                    current.write(f"{image_ref}\n")


def create_image_urls(paths):
    for path in paths:
        atom_hash = Path(path).name.split(".")[0] #or plain 2md5
        image_base_url_path = Path(f"{Path(path).parents[1]}/image_base_url.txt")
        with open(path, mode="r") as current:
            urls = current.readlines()

        image_base_url = ""

        if image_base_url_path.is_file():
            with open(image_base_url_path, mode="r") as current:
                image_base_url = current.readline().strip()

        target_path = f"{Path(path).parent}/{atom_hash}.image_urls.txt"

        with open(target_path, mode="w", encoding="utf-8") as out_file:
            for url in urls:
                image_url = url.strip()
                if image_base_url not in ["None", "Invalid", ""]:
                    image_url = f"{image_base_url}/{image_url}"

                out_file.write(f"{image_url}\n")



if __name__ == "__main__":
    p = {
        "root_dir": ".",
        "target_dir": "{root_dir}/data/leech_db"
    }

# params
args, _ = fargv.fargv(p)

#get image-refs ✓
## fonds 
fond_paths = get_path_list(args.target_dir, ".FO.preferences.xml")
image_base_dict = get_image_base_urls(fond_paths, mode="archive")
create_image_base_url_files(image_base_dict)
print("\n")

## collections
collection_paths = get_path_list(args.target_dir, ".CO.cei.xml")
image_base_dict = get_image_base_urls(collection_paths, mode="collection")
create_image_base_url_files(image_base_dict)
print("\n")

# build image urls from refs ✓
## refs
charter_paths = get_path_list(args.target_dir, ".CH.cei.xml")
create_image_refs(charter_paths)
print("\n")

## urls
image_refs_list = get_path_list(args.target_dir,  ".image_refs.txt")
create_image_urls(image_refs_list)



