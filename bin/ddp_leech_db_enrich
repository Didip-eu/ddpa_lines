#!/usr/bin/env python3

"""
Leeches .xml-files in target file structure system with the main purpose of building image urls.
"""

# TODO: discuss namespaces and whether there should be empty txt files for those fonds that have none (or have empty ones) (but their image urls in the cei files)
# TODO: build image urls in enrich -> for those starting with http:// or https, take url directly; otherwise: build from parent curation base url.txt + url attribute 

# TODO: # def cei charter file -> cei.xml (without atomid?); create url.txt (charter url)
# TODO:
    # dict: atomid of charter -> md5sum of image
    # dict: image url/image filename -> md5sum of image


# TODO: discuss merging two diplomatic units/images (e.g. when charter pictured in two different places)


import os
import random
from pathlib import Path
from pathlib import PurePosixPath
from pprint import pprint
import shutil
from typing import Dict, Generator, List, Literal, get_args # where to put choices in program?
from lxml import etree
import fargv
from tqdm import tqdm
import hashlib
import glob
from urllib.parse import urlparse

from ddp_util import decompose_chatomid, get_path_generator, get_path_list


### Type options
base_url_choices = Literal["archive", "collection"] #TODO: see top


def filter_image_base_url(image_base):
    exceptions = ["www.monasterium.net",
    "www.monasterium.net/",
    "www.monasterium.net/*",
    "images.monasterium.net/*",
    "http://www.monasterium.net/",
    "http://www.monasterium.net",
    "http://www.monasterium.net/*",
    "http://images.monasterium.net/*",
    "http://www.monasterium.net/Diplomatico_Viewerbild.jpg"]

    if image_base in exceptions:
        image_base = "Invalid"#TODO: generalize and extend this to empty strings, which are now handled in the get_image_base_urls function
    return image_base
    

def get_image_base_urls(paths, mode: base_url_choices):
    """
    Returns (filtered) base image paths.
    """
    options = get_args(base_url_choices)
    assert mode in options, f"'{mode}' is not in {options}"

    pprint("Parsing curation image base paths.")

    file_locations = {}
    namespaces = {"xrx": "http://www.monasterium.net/NS/xrx", "atom": "http://www.w3.org/2005/Atom", "cei": "http://www.monasterium.net/NS/cei"}

    if mode == "archive":
        pprint("Mode: archives")        
        for file in tqdm(paths):
            with open(file, 'r', encoding='utf-8') as current:
                tree = etree.parse(current)
                image_server_base_url = "".join(tree.xpath("//xrx:param[@name='image-server-base-url']/text()", namespaces = namespaces))
                image_base = filter_image_base_url("None" if (image_server_base_url  == "") else image_server_base_url)
                image_access = tree.xpath("xrx:param[@name='image-access']/text()", namespaces = namespaces)
                restricted = True if image_access == ("free" or "Free") else False #have not seen capitalized F but just to make sure..
                file_locations[file] = image_base 
    elif mode =="collection":
        pprint("Mode: collections")
        for file in tqdm(paths):
            with open(file, 'r', encoding='utf-8') as current:
                tree = etree.parse(current)
                image_server_address = "".join(tree.xpath("//cei:image_server_address/text()", namespaces = namespaces))
                image_server_folder = "".join(tree.xpath("//cei:image_server_folder/text()", namespaces = namespaces))              
                image_base = filter_image_base_url("None" if ((image_server_address or image_server_folder) == "") else f"{image_server_address}/{image_server_folder}") #TODO: check for misconstruced ones by adding http://
                file_locations[file] = image_base
                restricted = False #default since it's unclear whether <cei:publicationStmt><cei:availability n="ENRICH" status="restricted"/></cei:publicationStmt> in fonds plays any role
    # TODO: #also maybe relevant <xrx:keyword>Retrodigitalisierte Urkundeneditionen</xrx:keyword> bzw. <cei:sourceDesc><cei:p>Export aus Google Daten</cei:p>
    else:
        raise ValueError("Invalid mode.")
    #pprint(file_locations)    
    return file_locations, restricted


def create_image_base_url_files(file_locations):
    """
    Creates .txt-files with the image base url at curation-level.
    """
    pprint("Creating .txt files at curation-level.")

    for path, image_base in tqdm(file_locations.items()):
        file_path = Path(path)
        target_path = f"{file_path.parent}/image_base_url.txt"
        #target_path = f"{file_path.parent}/{file_path.with_suffix('').stem}.image_base_url.txt"
        if image_base != "":
            with open(target_path, 'w', encoding="utf-8") as p:
                p.write(image_base)
        else:
            continue


def create_image_refs(paths): #here, refs is understood as a reference to an object, be it a valid URL or a file-name that is later resolved
    pprint("Parsing charter files for image paths. Building image refs on charter level.")

    namespaces = {"xrx": "http://www.monasterium.net/NS/xrx", "atom": "http://www.w3.org/2005/Atom", "cei": "http://www.monasterium.net/NS/cei"}

    for file_path in tqdm(paths):
        with open(file_path, 'r', encoding='utf-8') as current:
            tree = etree.parse(current)
            original = tree.xpath("//cei:witnessOrig/cei:figure/cei:graphic/@url", namespaces = namespaces)
            copy = tree.xpath("//cei:witness/cei:figure/cei:graphic/@url", namespaces = namespaces)
        file_path = Path(file_path)
        file_folder = file_path.parent
        images = original + copy
        if len(original) != 0: #or bool "if not original: ~ empty string bool logic"
            image_status = "ORIG"
        elif len(copy) != 0:
            image_status = "COPY"
        else:
            image_status = "NONE" #is never invoked since empty list is not iterated
        for i, j in enumerate(images):
            target_path = f"{file_folder}/{file_folder.stem}.{i}.{image_status}.image_ref.txt"
            with open(f"{target_path}", "w", encoding="utf-8") as txt:
               txt.write(j)


def create_image_urls(paths):
    for path in paths:
        atom_hash = Path(path).name.split(".")[0] #or plain 2md5
        image_base_path = Path(f"{Path(path).parents[1]}/image_base_url.txt")
        with open(path, mode="r") as current:
            image_ref = current.readline()
        if image_base_path.is_file():
            with open(image_base_path, mode="r") as current:
                image_base_url = current.readline()
                if image_base_url == ("None" or "Invalid"):
                    image_url = image_ref
                else:
                    image_url = f"{image_base_url}/{image_ref}"
        else:
            image_url = image_ref        
        target_path = Path(f"{Path(path).parent}/{atom_hash}.image_urls.txt")
        with open(target_path, mode="a", encoding="utf-8") as current:
            current.write(f"{image_url}\n")


# def create_image_urls_json:
# for successful leeches -> image_urls.json ( {"hash.imageformat": "url", etc.})

# quality of life scripts:              

if __name__ == "__main__":
    p = {
        "root_dir": ".",
        #"charter_dir": "{root_dir}/data/db_subsample",
        "charter_dir": "{root_dir}/data/db/mom-data/metadata.charter.public",
        "collection_dir": "{root_dir}/data/db/mom-data/metadata.collection.public",
        "archive_dir": "{root_dir}/data/db/mom-data/metadata.archive.public",
        "fond_dir": "{root_dir}/data/db/mom-data/metadata.fond.public",
        "target_dir": "{root_dir}/data/tmp/data/leech_db"
    }

# params
args, _ = fargv.fargv(p)
print("\n")

# get image-refs ✓
## fonds 
# fond_paths = get_path_list(args.target_dir, ".FO.preferences.xml")
# image_base_dict, _ = get_image_base_urls(fond_paths, mode="archive")
# create_image_base_url_files(image_base_dict)
# print("\n")

# ## collections
# collection_paths = get_path_list(args.target_dir, ".CO.cei.xml")
# image_base_dict, _ = get_image_base_urls(collection_paths, mode="collection")
# create_image_base_url_files(image_base_dict)
# print("\n")

# # build image urls from refs ✓
# ## refs
# charter_paths = get_path_list(args.target_dir, ".CH.cei.xml")
# create_image_refs(charter_paths)
# print("\n")

## urls
image_refs_list = get_path_list(args.target_dir,  ".image_ref.txt")
create_image_urls(image_refs_list)



